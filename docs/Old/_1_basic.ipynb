{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOZ9cX64g6bU5cx20bc6LKf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# picd : Python Implementation of Causal Discovery"],"metadata":{"id":"SXC1X7wdNPMc"}},{"cell_type":"markdown","source":["##  picd.causal_discovery.constraint_based_algorithm.basic"],"metadata":{"id":"WQJlsgu8Ezs3"}},{"cell_type":"markdown","source":["Basic algorithm of many constraint-based algorithm(ex : pc algorithm).\n","\n","\n","**\\[Assumption\\]**\n","\n","\n","- No hidden confounder Assumption\n","- Markov Causal Assumption\n","- Faithfulness Assumption\n","\n","\n","**\\[Process\\]**\n","\n","- Find Skeleton by relation of adjacency and d-separation**\n","- **→ Find V-structure by lemma 1 (Verma and Pearl, 1991)**\n","- **→ Apply Meek’s rule (Meek, 1995)**\n","- **→ Proof Soundness and Completeness with DAG pattern by the theorem of Meek (Meek, 1995)**\n","\n","\n","For more information, see *Note* below.\n"],"metadata":{"id":"GBDZAncAEll-"}},{"cell_type":"markdown","source":["### class picd.causal_discovery.constraint_based_algorithm.basic(void)"],"metadata":{"id":"haIDQydQFBtF"}},{"cell_type":"markdown","source":["#### Methods"],"metadata":{"id":"3Mb4q6Y1GIwD"}},{"cell_type":"markdown","source":["##### identify(data:pd.DataFrame, ind:str) -> picd.pattern"],"metadata":{"id":"2a_cHR-AGMfE"}},{"cell_type":"markdown","source":["\n","\n","*   Return : DAG pattern\n","\n"],"metadata":{"id":"GMD-oopfHrXB"}},{"cell_type":"markdown","source":["###### Pseudo Code"],"metadata":{"id":"ZRCdtX0sLHhO"}},{"cell_type":"markdown","source":["Metropolitan, 2004, Learning Bayesian Networks, chapter 10, pp.546"],"metadata":{"id":"PwMzeAPR3jc4"}},{"cell_type":"markdown","source":["\n","\n","```\n","Problem : Given a set IND of d-separations, determine the DAG pattern faithful\n","to IND if there is one\n","\n","Input : a set V of nodes and a set IND of d-separations among subsets of the\n","nodes\n","\n","Outputs : If IND admits a faithful DAG representation, the DAG pattern gp\n","containing the d-separations in this set\n","\n","# The original code is C-style, so I modify the code to be similar to Python style.\n","# Warning : the notations in this code are not in the original code. I wrote it. \n","#           So, the notations are possibly wrong\n","\n","def find_DAG_pattern(V, IND, Empty Graph G) -> Graph G:\n","\tS[(x,y)] <- A list containing the set Sxy \n","\t\t\t\t\t\t\tthat render X and Y are conditional independent\n","\n","\tfor each pair of nodes (X, Y) in V:\n","\t\t# step 0\n","\t\tfor subset S_ in V/{X, Y}:\n","\t\t\tif I({X},{Y}|S_) in IND: \n","\t\t\t\tS[(X,Y)].append(S_)\n","\t\t\n","\t\tif S[(X,Y)] is empty:\n","\t\t\t# step 1\n","\t\t\t# Lemma 1, Verma and Pearl, 1991, On the Equivalence of Causal Models\n","\t\t\t# https://arxiv.org/abs/1304.1108\n","\t\t\t# S[(X, Y)] is empty <-> X and Y are adjacent\n","\t\t\tcreate the link X - Y in G\n","\t\n","\tfor each uncoupled meeting X - Z - Y in V:\n","\t\t# step 2\n","\t\t# v-structure property\n","\t\tif Z not in every S in S[(X, Y)]:\n","\t\t\torient X - Z - Y as X -> Z <- Y\n","\t\n","\twhile more edges can be oriented:\n","\t\t# step 3\n","\t\tfor each uncoupled meeting X -> Z - Y:\n","\t\t\t# X -> Z - Y is not v-structure, therefore \n","\t\t\torient Z - Y  as Z -> Y\n","\t\t# step 4\n","\t\tfor each link X - Y such that there is a path from X to Y:\n","\t\t\t# Given graph G is DAG, therefore there is not cyclic path between X and Y\n","\t\t\t# However, if Y -> X, then there is cyclic path : X -> ... -> Y -> X\n","\t\t\t# thus\n","\t\t\torient X - Y as X -> Y\n","\t\t# step 5\n","\t\tfor each uncoupled meeting X - Z - Y such that X -> W, Y -> W, and Z - W:\n","\t\t\t# X - Z - Y is not v-structure -> Z is parent of either X or Y\n","\t\t\t# if Z <- W, there is cyclic path through either X or Y \n","\t\t\t# thus\n","\t\t\torient Z - W as Z -> W\n","\t\n","\n","\treturn G\n","  ```\n","\n"],"metadata":{"id":"C8CJb2le3eye"}},{"cell_type":"markdown","source":["###### Source Code"],"metadata":{"id":"ncyji2MULP-_"}},{"cell_type":"code","source":[],"metadata":{"id":"LvRxpJ7BLV7h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Note"],"metadata":{"id":"BLC3N1U8HLgm"}},{"cell_type":"code","source":[],"metadata":{"id":"yhL0Oy_FKJ6X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **The name ‘basic algorithm’ is appropriate. It effectively illustrates the primary framework of Constraint-based algorithms.**\n","    - **Find Skeleton by relation of adjacency and d-separation**\n","    - **→ Find V-structure by lemma 1 (Verma and Pearl, 1991)**\n","    - **→ Apply Meek’s rule (Meek, 1995)**\n","    - **→ Proof Soundness and Completeness with DAG pattern by the theorem of Meek (Meek, 1995)**\n","- **Theorem)**\n","***If the set of d-separations, which are the input to the basic algorithm, admit a faithful DAG representation, the algorithm creates the DAG pattern containing the d-separations in this set***\n","    - In the other word, every link and directed edge in the DAG pattern created by the basic algorithm is ***sound*** and ***complete*** with link and directed edge in DAG pattern containing the d-separations in this set\n","    - **This theorem is veeeeeeeeeeeeeeeeeeery important**\n","        - Because we can indirectly prove the soundness and completeness of our new constraint-based algorithm through this basic algorithm\n","        - Example) PC algorithm modifies step 0 & 1 in the basic algorithm to improve efficiency. Also, conservative PC algorithm additionally modifies step 3 in PC algorithm.\n","    - **This theorem is proved by the next 3 step**\n","        - *1) If the set of d-separations, which are the input to Algorithm 10.1, admit a faithful DAG representation, the algorithm creates a link between X and Y if and only if there is a link between X and Y in the DAG pattern gp containing the d-separations in this set*\n","            - (pf) See the notation of step 1 in above code\n","        - *2) If the set of d-separations, which are the input to Algorithm 10.1, admit a faithful DAG representation, then any directed edge created by the algorithm is a directed edge in the DAG pattern containing the d-separations in this set. **(soundness)***\n","            - (pf) See the notations of step 2 ~ 5. They are induced only by given assumption and the definition of DAG. If there is a directed edge which does not included in the true DAG pattern, a contradiction arises.\n","        - 3) *If the set of d-separations, which are the input to Algorithm 10.1, admit a faithful DAG representation, all the directed edges, in the DAG pattern containing the d-separations in this set, are directed by the algorithm. **(completeness)***\n","            - (pf) See the appendix of <Causal inference and causal explanation with background knowledge> (Meek, 1995). This proof is difficult unlike the previous step\n","- **Note that step 0 & 1 make the algorithm teribbly inefficient, because the number of all combinatorial subsets is  $2^{n-2}$**"],"metadata":{"id":"5DfQ-Yf54BMA"}},{"cell_type":"markdown","source":["*Basic algorithm* is the basis of many constraint-based algorithms, such as pc algorithm. It illustrates the primary framework of constraint-based algorithms and returns soundful and correct DAG pattern for given : \n","\n","1. **Find Skeleton by relation of adjacency and d-separation**\n","2. **Find V-structure by lemma 1 (Verma and Pearl, 1991)**\n","3. **Apply Meek’s rule (Meek, 1995)**\n","4. **Proof Soundness and Completeness with DAG pattern by the theorem of Meek (Meek, 1995)**\n","\n"],"metadata":{"id":"uxaRjL7Q4cnh"}},{"cell_type":"markdown","source":["#### Parameter"],"metadata":{"id":"we1PnJsKH8h_"}},{"cell_type":"markdown","source":["\n","*   **data**-observed data. It interprets the columns of *data* as the vertexs of DAG which generated *data*.\n","*   **vertex**-vertex array like {'A', 'B', 'C'}. If it is None, vertex set is automatically filled by the colnames of *data*."],"metadata":{"id":"xGD4tkjFIDuE"}},{"cell_type":"markdown","source":["### Example"],"metadata":{"id":"vBus8oz90OJz"}},{"cell_type":"markdown","source":["#### Example"],"metadata":{"id":"RjqXiPq_0bzp"}},{"cell_type":"code","source":["from tqdm import tqdm\n","from collections import deque\n","from itertools import combinations, chain\n","\n","def identify_skeleton_from_empty_graph(self, data, test_kwarg):\n","    self.ptn = pattern()\n","    self.ptn.add_vertex(list(data.columns))\n","\n","    self.p_independence_set = defaultdict(set)\n","    self.p_independence_set = defaultdict(lambda: defaultdict(set))\n","    \n","    pairs = combinations(self.ptn.vertex, 2)\n","    for x, y in pairs:\n","        v_not_x_y = list(self.ptn.vertex - {x, y})\n","        power_set_of_v_not_x_y = chain(*[combinations(v_not_x_y, n) for n in range(len(v_not_x_y) + 1)])\n","        for subset in power_set_of_v_not_x_y:\n","            if self.test(data, {x}, {y}, set(subset), **test_kwarg):\n","                self.p_independence_set[x][y]\n","                self.p_independence_set[y][x] = self.p_independence_set[x][y]\n","                self.p_independence_set[x][y].add(subset)\n","                # self.p_independence_set[y][x].add(subset)\n","\n","    self.identify_skeleton_by_ind(self.p_independence_set)\n","\n","def identify_skeleton_by_ind(self, ind, vertex:set = None):\n","    if vertex is not None: self.ptn.add_vertex(vertex)\n","    \n","    self.p_independence_set = ind\n","    pairs = combinations(self.ptn.vertex, 2)\n","\n","    for x, y in pairs:\n","        if len(self.p_independence_set[x][y]) == 0:\n","            self.ptn.add_link(x, y)\n","\n","        # if x not in self.p_independence_set.keys():\n","        #     if y not in self.p_independence_set[x].keys():\n","        #         self.ptn.add_link(x, y)\n","    \n","\n","def identify_v_structure_with_adjacency_orient_faithfulness(self):\n","    uncoupled_triple = deque()\n","    for x in self.ptn.link.keys():\n","        for z in self.ptn.link[x].keys():\n","            for y in self.ptn.link[z].keys():\n","                # Test x-z-y is uncoulped meeting\n","                if x != y and not self.ptn.is_adjacent(x, y): \n","                    if all(z not in subset for subset in self.p_independence_set[x][y]) : uncoupled_triple.append((x, y, z))\n","    \n","    while uncoupled_triple:\n","        x, y, z = uncoupled_triple.popleft()\n","        #if Z not in every S in S[(X, Y)]:\n","        # orient X - Z - Y as X -> Z <- Y\n","        self.ptn.remove_links([(x,z), (y,z)])\n","        self.ptn.add_edges([(x,z), (y,z)])\n","\n","\n","def identify_meeks_rule_2(self):\n","    uncoupled_triple = deque()\n","    for x in self.ptn.child.keys():\n","        for z in self.ptn.child[x].keys():\n","            for y in self.ptn.link[z].keys():\n","                # Test x-z-y is uncoulped meeting\n","                if x != y and not self.ptn.is_adjacent(x, y): uncoupled_triple.append((x, y, z))\n","\n","    if len(uncoupled_triple) == 0: return False\n","\n","    while uncoupled_triple:\n","        x, y, z = uncoupled_triple.popleft()\n","        # X -> Z - Y is not v-structure, therefore \n","        # orient Z - Y  as Z -> Y\n","        self.ptn.remove_links([(y,z)])\n","        self.ptn.add_edges([(z,y)])\n","\n","    return True\n","\n","\n","def identify_meeks_rule_3(self):\n","    pairs = deque()\n","    for x in self.ptn.link.keys():\n","        for y in self.ptn.link[x].keys(): \n","            if len(self.ptn.get_path(x, y, directed=True)) > 0: pairs.append((x, y))\n","    \n","    if len(pairs) == 0: return False\n","\n","    while pairs:\n","        x, y = pairs.popleft()\n","        #Given graph G is DAG, therefore there is not cyclic path between X and Y\n","        # However, if Y -> X, then there is cyclic path : X -> ... -> Y -> X\n","            # thus orient X - Y as X -> Y\n","        self.ptn.remove_links([(x,y)])\n","        self.ptn.add_edges([(x,y)])\n","    \n","    return True\n","\n","\n","def identify_meeks_rule_4(self):\n","    pairs = deque()\n","    for w in self.ptn.parent.keys():\n","        # Find W which has more than two parents and vertex Z linked with\n","        if len(self.ptn.parent[w].keys()) >= 2 and w in self.ptn.link.keys():\n","            linked_with_w = set(self.ptn.link[w].keys())\n","\n","            # Find pair of parents of W (x, y) such that x is not adjacent with y\n","            # X   Y\n","            #  \\ /\n","            #   ><\n","            #   W\n","            parent_of_w = list(self.ptn.parent[w].keys())\n","            xy = combinations(parent_of_w, 2)\n","\n","            for x, y in xy:\n","                if not self.ptn.is_adjacent(x, y):\n","\n","                    # Find Z such that X - Z, Y - Z, and W - Z\n","                    linked_with_x = set(self.ptn.link[x].keys())\n","                    linked_with_y = set(self.ptn.link[y].keys())\n","                    linked_with_x_y_w = linked_with_w & linked_with_x & linked_with_y\n","\n","                    for z in linked_with_x_y_w: pairs.append((z, w))\n","    \n","    if len(pairs) == 0: return False\n","    while pairs:\n","        z, w = pairs.popleft()\n","        # Now, we know that \n","        # X - Z - Y\n","        #  \\  |  /\n","        #   > W <\n","        # X - Z - Y is not v-structure -> Z is parent of X or Y\n","        # if Z <- W, there is cyclic path through X or Y \n","        # thus orient Z - W as Z -> W\n","\n","        self.ptn.remove_links([(z,w)])\n","        self.ptn.add_edges([(z,w)])\n","\n","    return True"],"metadata":{"id":"ijjB-OOjnaIn","executionInfo":{"status":"ok","timestamp":1679202300802,"user_tz":-540,"elapsed":278,"user":{"displayName":"김익명","userId":"07651831371151580605"}}},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":["##### pattern"],"metadata":{"id":"XOPsJslKMewO"}},{"cell_type":"code","source":["from collections import deque\n","from itertools import combinations, chain\n","from collections import defaultdict\n","\n","\n","class pattern:\n","    def __init__(self, vertex = None, edges = None, links = None):\n","        self.vertex = set()\n","        self.parent = dict()\n","        self.child = dict()\n","        self.link = dict()\n","\n","        self.link_count = 0\n","\n","        self.add_vertex(vertex)\n","        self.add_edges(edges)\n","        self.add_links(links)\n","\n","        self.d_separation_set = defaultdict(lambda: defaultdict(set))\n","    \n","    def add_vertex(self, vertex) -> None:\n","        if vertex: \n","            for v in vertex:\n","                if v not in self.vertex:\n","                    self.vertex.add(v)\n","                    self.parent[v] = dict()\n","                    self.child[v] = dict()\n","                    self.link[v] = dict()\n","\n","\n","    def remove_vertex(self, vertex) -> None:\n","        for v in vertex:\n","            self.vertex.remove(v)\n","\n","            for p in self.parent[v].keys():\n","                self.child[p].pop(v, None)\n","            \n","            for c in self.child[v].keys():\n","                self.parent[c].pop(v, None)\n","            \n","            for l in self.link[v].keys():\n","                self.remove_links((l,v))\n","            \n","            self.parent.pop(v, None)\n","            self.child.pop(v, None)\n","            self.link.pop(v, None)\n","\n","    def add_edge(self, v1,  v2, **attribute)->None:\n","        self.add_vertex([v1, v2])\n","\n","        self.parent[v2][v1] = attribute\n","        self.child[v1][v2] = attribute\n","\n","\n","    def add_edges(self, edges) -> None:\n","        if edges:\n","            for e in edges:\n","                if isinstance(e, dict):\n","                    v1 = e['v1']; v2 = e['v2']\n","                    del e['v1']; del e['v2']\n","                    self.add_edge(v1, v2, **e)\n","                elif len(e) == 2:\n","                    self.add_edge(*e)\n","                else:\n","                    arg = dict()\n","                    i = 0\n","                    for attr in e[2:]:\n","                        arg[f'A{i}'] = attr\n","                        i += 1\n","                    self.add_edge(e[0], e[1], **arg)\n","\n","\n","    def remove_edges(self, edges) -> None:\n","        for e in edges:\n","            pa, ch = e\n","            del self.parent[ch][pa]\n","            del self.child[pa][ch]\n","\n","            exist1 = self.parent[ch].pop(pa, None)\n","            exist2 = self.child[pa].pop(ch, None)\n","\n","            if exist1 is not None and exist2 is not None:\n","                self.link_count -= 1\n","            elif not (exist1 is None and exist2 is None):\n","                print(f'remove_edges : the edge between {v1} and {v2} is not matched with self.parent and self.child!')\n","\n","    def add_link(self, v1, v2, **attribute) -> None:\n","        self.add_vertex([v1, v2])\n","\n","        self.link[v1][v2] = attribute\n","        self.link[v2][v1] = attribute\n","        \n","        self.link_count += 1\n","\n","    def add_links(self, links) -> None:\n","        if links:\n","            for l in links:\n","                if isinstance(l, dict):\n","                    v1 = l['v1']; v2 = l['v2']\n","                    del l['v1']; del l['v2']\n","                    self.add_link(v1, v2, **l)\n","                elif len(l) == 2:\n","                    self.add_link(*l)\n","                else:\n","                    arg = dict()\n","                    i = 0\n","                    for attr in l[2:]:\n","                        arg[f'A{i}'] = attr\n","                        i += 1\n","                    self.add_link(l[0], l[1], **arg)\n","\n","    def remove_links(self, links) -> None:\n","        for l in links:\n","            v1, v2 = l\n","\n","            exist1 = self.link[v1].pop(v2, None)\n","            exist2 = self.link[v2].pop(v1, None)\n","\n","            if exist1 is not None and exist2 is not None:\n","                self.link_count -= 1\n","            elif not (exist1 is None and exist2 is None):\n","                print(f'remove_links : there are unsymmetric links between {v1} and {v2}!')\n","            \n","    def is_adjacent(self, v1, v2):\n","        return v1 in self.link[v2].keys() or v1 in self.child[v2].keys() or v1 in self.parent[v2].keys() \n","\n","    def get_ancestor(self, vertex) -> set:\n","        visited = {v:0 for v in self.vertex}\n","        visited[vertex] = 1\n","        result = set()\n","\n","        queue = deque([vertex])\n","\n","        while queue:\n","            v = queue.popleft()\n","            for v1 in self.parent[v].keys():\n","                if not visited[v1]:\n","                    visited[v1] = 1\n","                    result.add(v1)\n","                    queue.append(v1)\n","        \n","        return result\n","\n","    def get_descendant(self, vertex) -> set:\n","        visited = {v:0 for v in self.vertex}\n","        visited[vertex] = 1\n","        result = set()\n","\n","        queue = deque([vertex])\n","\n","        while queue:\n","            v = queue.popleft()\n","            for v1 in self.child[v].keys():\n","                if not visited[v1]:\n","                    visited[v1] = 1\n","                    result.add(v1)\n","                    queue.append(v1)\n","        \n","        return result\n","\n","    def get_path(self, source, target, directed = True):\n","        return self.get_path_(source, target, directed=directed)\n","    \n","    def get_path_(self, v1, v2, trace = None, initial = True, directed = True):\n","        if initial:\n","            self.visited = {v:0 for v in self.vertex}\n","            self.visited[v1] = 1\n","            self.result = []\n","            trace = [v1]\n","        \n","        for v in self.child[v1].keys():\n","            if v == v2:\n","                self.result.append(trace + [v2])\n","            else:\n","                if not self.visited[v]:\n","                    new_trace = trace + [v]\n","                    self.visited[v] = 1\n","                    self.get_path_(v, v2, new_trace, False, directed)\n","                    self.visited[v] = 0\n","        \n","        if not directed:\n","            for v in self.parent[v1].keys():\n","                if v == v2:\n","                    self.result.append(trace + [v2])\n","            else:\n","                if not self.visited[v]:\n","                    new_trace = trace + [v]\n","                    self.visited[v] = 1\n","                    self.get_path_(v, v2, new_trace, False, directed)\n","                    self.visited[v] = 0\n","        \n","        return self.result #2d list  \n","    \n","    def is_cyclic(self) -> bool:\n","        # Code Resource : https://www.geeksforgeeks.org/detect-cycle-in-a-graph/\n","        visited = {v:0 for v in self.vertex}\n","        recStack =  {v:0 for v in self.vertex}\n","\n","        for v in self.vertex:\n","            if not visited[v]:\n","                if self.is_cyclic_util(v, visited, recStack): return True\n","        \n","        return False\n","        \n","    \n","    def is_cyclic_util(self, v, visited, recStack) -> bool:\n","        visited[v] = 1\n","        recStack[v] = 1\n","\n","        for ch in self.child[v].keys():\n","            if not visited[ch]:\n","                if self.is_cyclic_util(ch, visited, recStack):\n","                    return True\n","            elif recStack[ch]:\n","                return True\n","        \n","        recStack[v] = 0\n","        return False\n","\n","    def get_d_separation(self, X, Z) -> set:\n","        # Test X and Z are disjoint\n","        if X & Z:\n","            print('get_d_separation : given two vertex sets are not disjoint!')\n","            return\n","        \n","        # Test this pattern is DAG or not\n","        if self.link_count > 0:\n","            print('get_d_separation : this is not DAG. there is a link in this pattern!')\n","            return\n","\n","        # 1) make descendent list \n","        descendent = {v:0 for v in self.vertex}\n","        for i in self.vertex:\n","            descendent_of_i = self.get_descendant(i)\n","            if descendent_of_i&Z or i in Z:\n","                descendent[i] = 1\n","        \n","        # 2) make undirected version of this DAG\n","        sym_graph = {v: [] for v in self.vertex}\n","        for pa, chs in self.child.items():\n","            chs = chs.keys()\n","            for ch in chs:\n","                sym_graph[pa].append([ch, 0]) # [vertex, label]\n","                sym_graph[ch].append([pa, 0])\n","        \n","        # 3) for each x in X, find vertex v such that v and x are d-separated by Z \n","        # ez explanation  1) do BFS from 's' in undirected graph we create above\n","        #                 2) whenever you meet another vertex v in V/X, \n","        #                    check the trail 'previous-current-v' is 'active' or not\n","        #                 3) If the trail is active, v and x are not d-separated by Z.\n","        #                    Save this fact and append edges v ->its neiborhood to queue\n","        #                 4) If the trail is not active, stop searching along the trail\n","        reachable = set()\n","        queue = deque()\n","        for v in X:\n","            queue.append(('', v))\n","        \n","        while queue:\n","            #v1 -> v2\n","            v1, v2 = queue.popleft()\n","\n","            for i, v3 in enumerate(sym_graph[v2]):\n","                v3, label = v3\n","                if not label and v1 != v3:\n","                    # test whether the trail 'v1-v2-v3' is active\n","                    # first, check : given triple (v1, v2, v3) are v-structure & descendent[v2] = 1\n","                    if v1 in self.parent[v2].keys() and v3 in self.parent[v2].keys(): \n","                        if descendent[v2]:\n","                            reachable.add(v3)\n","                            sym_graph[v2][i][1] = 1 # labeling\n","                            queue.append((v2, v3))\n","\n","                    # second, check : given triple (v1, v2, v3) are NOT v-structure & v2 NOT in Z\n","                    elif v2 not in Z:\n","                        reachable.add(v3)\n","                        sym_graph[v2][i][1] = 1 # labeling\n","                        queue.append((v2, v3))\n","\n","        Ys = self.vertex - (reachable|X|Z)\n","        # if len(Ys) > 0:\n","        #   for Y in Ys:\n","        #       self.add_d_separations([(X, {Y}, Z)])\n","\n","        return (X, Ys, Z)\n","\n","    def d_separated(self, X, Y, Z) -> bool:\n","        # Warning : This method is terribly inefficient\n","        return Y <= self.get_d_separation(X, Z)[1]\n","    \n","    def full_link(self):\n","        temp_vertex = list(self.vertex)\n","        for i, v1 in enumerate(temp_vertex[:-1]):\n","            for v2 in temp_vertex[i + 1 :]:\n","                self.add_link(v1, v2)\n","    \n","    def draw(self):\n","        for v1 in self.vertex:\n","          for v2 in self.child[v1].keys():\n","            print(f'{v1} -> {v2} {self.child[v1][v2]}')\n","\n","        for v1 in self.vertex:\n","          for v2 in self.link[v1].keys():\n","            print(f'{v1} - {v2} {self.link[v1][v2]}')\n","\n","    \n","    def add_d_separations(self, d_separation_set):\n","        for ds in d_separation_set:\n","            x, y, z = ds\n","            x, y= x.pop(), y.pop()\n","            z = tuple(z)\n","\n","            self.d_separation_set[x][y]\n","            self.d_separation_set[y][x] = self.d_separation_set[x][y]\n","            self.d_separation_set[x][y].add(z)\n","            # self.d_separation_set[y+x].add(z)\n","    \n","    def get_all_d_separation(self) -> dict:\n","        pairs = combinations(self.vertex, 2)\n","        for x, _ in pairs:\n","            v_not_x_and_some_v = list(self.vertex - {x, _})\n","            power_set = chain(*[combinations(v_not_x_and_some_v, n) for n in range(len(v_not_x_and_some_v))])\n","\n","            for z in power_set:\n","                z = set(z)\n","                ys = self.get_d_separation({x}, z)[1]\n","                if len(ys) > 0:\n","                    for y in ys:\n","                        self.add_d_separations([({x}, {y}, z)])\n","\n","        return self.d_separation_set"],"metadata":{"id":"QpXZLPUknbUO","executionInfo":{"status":"ok","timestamp":1679202301483,"user_tz":-540,"elapsed":340,"user":{"displayName":"김익명","userId":"07651831371151580605"}}},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":["##### 시발"],"metadata":{"id":"i94SpjQMMgt0"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import scipy.stats as stats\n","from scipy.spatial.distance import pdist, squareform\n","\n","def gaussian_kernel(data:pd.DataFrame, X:set, sigma:float = None, unit_variance:bool = False) -> np.array:\n","    X = data.loc[:, list(X)].to_numpy()#.transpose()\n","    if not unit_variance:\n","        X = X/X.std(axis=0)\n","\n","    # from https://stats.stackexchange.com/questions/15798/how-to-calculate-a-gaussian-kernel-effectively-in-numpy\n","    dist = squareform(pdist(X, 'euclidean'))\n","    if not sigma : \n","        n = len(dist)\n","        sigma = np.median(dist[np.triu_indices(n, k = 1)])\n","    K = np.exp(-dist**2/ (2*sigma**2))\n","    return K\n","\n","def centralized_gaussian_kernel(data:pd.DataFrame, X:set, sigma:float = None, unit_variance:bool = False) -> np.array:\n","    K = gaussian_kernel(data, X, sigma, unit_variance)\n","    n = len(K)\n","    H = np.identity(n) - np.ones((n, n))/n\n","    return np.matmul(np.matmul(H, K), H)\n","\n","def kcit(data:pd.DataFrame, X:set, Y:set, Z:set = None, regulation:float = 1e-3, alpha:float = 0.05, beta:float = 1, unit_variance:bool = False, **test_kwarg) -> bool:\n","    # hyper parameter setting\n","    hyper_parameter = dict()\n","\n","    if len(data) < 200: hyper_parameter['width'] = 0.8\n","    elif len(data) > 1200: hyper_parameter['width'] = 0.3\n","    else: hyper_parameter['width'] = 0.5 \n","\n","    for kw, value in test_kwarg.items():\n","        hyper_parameter[kw] = value\n","\n","    n = len(data)\n","    # Independence Test\n","    if Z is None:\n","        Kx = centralized_gaussian_kernel(data, X, unit_variance)\n","        Ky = centralized_gaussian_kernel(data, Y, unit_variance)\n","\n","        T = np.matmul(Kx, Ky).trace() / n\n","        E_T = Kx.trace() * Ky.trace() / (n**2)\n","        V_T = 2 * np.matmul(Kx, Kx).trace() * np.matmul(Ky, Ky).trace() / (n**4)\n","\n","        k = E_T**2 / V_T\n","        theta = V_T/E_T \n","    \n","    else:\n","        # X = [X, Z]\n","        X = X|Z\n","\n","        # Kx, Ky, Kz <- centralized kernel matrix of X, Y, Z with hyper_parameter['width']\n","        Kx = centralized_gaussian_kernel(data, X, hyper_parameter['width'])\n","        Ky = centralized_gaussian_kernel(data, Y, hyper_parameter['width'])\n","        Kz = centralized_gaussian_kernel(data, Z, hyper_parameter['width'])\n","        \n","        Rz = regulation * np.linalg.inv(Kz + regulation * np.identity(n))\n","        Kxz = np.matmul(np.matmul(Rz, Kx), Rz)\n","        Kyz = np.matmul(np.matmul(Rz, Ky), Rz)\n","\n","        Lxz, Vx = np.linalg.eig(Kxz)\n","        Lyz, Vy = np.linalg.eig(Kyz)\n","\n","        # soring eigenvalues and corresponding eigenvectors\n","        idx = Lxz.argsort()\n","        Lxz, Vx = Lxz[idx], np.real(Vx[:, idx])\n","        idx = Lyz.argsort()\n","        Lyz, Vy = Lyz[idx], np.real(Vy[:, idx])\n","\n","        # diag(Vx(Vy.T))\n","        W = np.zeros(n)\n","        for t in range(n):\n","            W[t] = np.inner(Vx[t], Vy[t])\n","\n","        # W = W(W.T)\n","        W = np.asmatrix(W)\n","        W = np.matmul(W, W.transpose())\n","\n","        T = np.matmul(Kxz, Kyz).trace().item()/n\n","        E_T = W.trace().item()/n\n","        V_T = 2 * np.matmul(W, W).trace().item()/(n**2)\n","    \n","        k = E_T**2 / V_T\n","        # theta = 1/np.log(E_T/V_T/np.power(n, 2/3)) \n","        theta = 1/np.log10(E_T/V_T) \n","        # theta = V_T/E_T * np.sqrt(n)\n","\n","    cri = stats.gamma(a = k, scale = theta).ppf(1 - alpha)\n","    \n","    return T < cri"],"metadata":{"id":"YmhPm5pxnobJ","executionInfo":{"status":"ok","timestamp":1679202302902,"user_tz":-540,"elapsed":1,"user":{"displayName":"김익명","userId":"07651831371151580605"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","class basic:\n","    def __init__(self):\n","        self.ptn = pattern()\n","        \n","        # self.identify_skeleton_from_empty_graph = identify_skeleton_from_empty_graph\n","        # self.identify_v_structure_with_adjacency_orient_faithfulness = identify_v_structure_with_adjacency_orient_faithfulness\n","        # self.identify_meeks_rule_2 = identify_meeks_rule_2\n","        # self.identify_meeks_rule_3 = identify_meeks_rule_3\n","        # self.identify_meeks_rule_4 = identify_meeks_rule_4\n","    \n","    def identify(self, data:pd.DataFrame = None, test:str = None, ind:dict = None, vertex = None, **test_kwarg) -> pattern: \n","      \n","        # self.data = data\n","\n","        # self.test = self.get_test(test)\n","        # self.test = mutual_information_test\n","        self.test = kcit\n","\n","\n","        # STEP 0 ~ 1 : Find skeleton\n","        if ind is not None:\n","            self.identify_skeleton_by_ind(ind, vertex)\n","        else:\n","            self.identify_skeleton_from_empty_graph(data, test_kwarg = test_kwarg)\n","\n","\n","        # # STEP 2 : Find v-structure\n","        self.identify_v_structure_with_adjacency_orient_faithfulness()\n","\n","        # STEP 3~5 : use Meek's rules\n","        cnt = True\n","        while cnt:\n","          cnt2 = self.identify_meeks_rule_2()\n","          cnt3 =  self.identify_meeks_rule_3()\n","          cnt4 =  self.identify_meeks_rule_4()\n","\n","          cnt = cnt2 or cnt3 or cnt4 # Check there are vertexs which could be changed\n","\n","        return self.ptn\n","\n","        \n","basic.identify_skeleton_from_empty_graph = identify_skeleton_from_empty_graph\n","basic.identify_v_structure_with_adjacency_orient_faithfulness = identify_v_structure_with_adjacency_orient_faithfulness\n","basic.identify_meeks_rule_2 = identify_meeks_rule_2\n","basic.identify_meeks_rule_3 = identify_meeks_rule_3\n","basic.identify_meeks_rule_4 = identify_meeks_rule_4\n","basic.identify_skeleton_by_ind = identify_skeleton_by_ind\n","# basic.test = kcit"],"metadata":{"id":"zJ3csqbFnjWA","executionInfo":{"status":"ok","timestamp":1679202597612,"user_tz":-540,"elapsed":298,"user":{"displayName":"김익명","userId":"07651831371151580605"}}},"execution_count":127,"outputs":[]},{"cell_type":"markdown","source":["#### Test 1"],"metadata":{"id":"Hl3N77eLDZta"}},{"cell_type":"code","source":["import numpy as np\n","import scipy.stats as stats\n","import pandas as pd\n","from collections import defaultdict\n","from itertools import combinations, chain\n","\n","data = pd.DataFrame()\n","error = stats.norm()\n","\n","data['A'] = stats.norm(loc = 3).rvs(size = 1000)\n","data['B'] = stats.norm(loc = 3).rvs(size = 1000)\n","data['D'] = stats.norm(loc = 3).rvs(size = 1000)\n","\n","data['C'] = 3 * data['A'] * data['B'] * data['D'] + error.rvs(size = 1000)\n","data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8dNbCPwFAcy","executionInfo":{"status":"ok","timestamp":1679201303801,"user_tz":-540,"elapsed":259,"user":{"displayName":"김익명","userId":"07651831371151580605"}},"outputId":"09ca94d9-bace-4313-9deb-9f24396971c8"},"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000, 4)"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["bsc = basic()\n","ptn = bsc.identify(data, test = '')"],"metadata":{"id":"Fg2R46V8FA4c","executionInfo":{"status":"ok","timestamp":1679202466254,"user_tz":-540,"elapsed":71737,"user":{"displayName":"김익명","userId":"07651831371151580605"}}},"execution_count":119,"outputs":[]},{"cell_type":"code","source":["# bsc.test = kcit"],"metadata":{"id":"kmZUi3pgPRx0","executionInfo":{"status":"ok","timestamp":1679202306908,"user_tz":-540,"elapsed":2,"user":{"displayName":"김익명","userId":"07651831371151580605"}}},"execution_count":115,"outputs":[]},{"cell_type":"code","source":["# bsc.identify_skeleton_from_empty_graph(data, {})"],"metadata":{"id":"cvvBm6tkORlB","executionInfo":{"status":"ok","timestamp":1679202378941,"user_tz":-540,"elapsed":71706,"user":{"displayName":"김익명","userId":"07651831371151580605"}}},"execution_count":116,"outputs":[]},{"cell_type":"code","source":["p_ind = bsc.p_independence_set\n","print('AB', p_ind['A']['B'])\n","print('AC', p_ind['A']['C'])\n","print('AD', p_ind['A']['D'])\n","print('BC', p_ind['B']['C'])\n","print('BD', p_ind['B']['D'])\n","print('CD', p_ind['C']['D'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1FWQGRY4FIk9","executionInfo":{"status":"ok","timestamp":1679202466254,"user_tz":-540,"elapsed":14,"user":{"displayName":"김익명","userId":"07651831371151580605"}},"outputId":"f5c20964-39d8-40ff-8576-676220170239"},"execution_count":120,"outputs":[{"output_type":"stream","name":"stdout","text":["AB {(), ('D',)}\n","AC set()\n","AD {(), ('B',)}\n","BC set()\n","BD {(), ('A',)}\n","CD set()\n"]}]},{"cell_type":"code","source":["bsc.ptn.draw()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UvqaOPvwjHFP","executionInfo":{"status":"ok","timestamp":1679202466254,"user_tz":-540,"elapsed":12,"user":{"displayName":"김익명","userId":"07651831371151580605"}},"outputId":"763ec73b-d111-4a8b-b7d8-545b6f26ffeb"},"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["A -> C {}\n","B -> C {}\n","D -> C {}\n"]}]},{"cell_type":"markdown","source":["#### Test 2"],"metadata":{"id":"R5MpFeQ9D0UM"}},{"cell_type":"code","source":["ptn = pattern()\n","ptn.add_edges([\n","    ('B', 'A'),\n","    ('C', 'A'),\n","    ('B', 'D'),\n","    ('C', 'D'),\n","    ('D', 'E')\n","])\n","ds = ptn.get_all_d_separation()"],"metadata":{"id":"fnz6mrC9D-TP","executionInfo":{"status":"ok","timestamp":1679202557176,"user_tz":-540,"elapsed":261,"user":{"displayName":"김익명","userId":"07651831371151580605"}}},"execution_count":125,"outputs":[]},{"cell_type":"code","source":["bsc = basic()\n","bsc.identify(ind = ds, vertex = ptn.vertex)\n","bsc.ptn.draw()"],"metadata":{"id":"5-8Iiu5okL-P","executionInfo":{"status":"ok","timestamp":1679202600851,"user_tz":-540,"elapsed":269,"user":{"displayName":"김익명","userId":"07651831371151580605"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ae84691-e230-45af-c729-d4691d9c1bf7"},"execution_count":128,"outputs":[{"output_type":"stream","name":"stdout","text":["C -> A {}\n","C -> D {}\n","B -> A {}\n","B -> D {}\n","D -> E {}\n"]}]},{"cell_type":"code","source":["ptn = pattern()"],"metadata":{"id":"VLVQxK2qDMRM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ptn.add_edges([\n","    ('A', 'D'),\n","    ('D', 'B'),\n","    ('B', 'E'),\n","    ('C', 'E'),\n","    ('C', 'F'),\n","    ('D', 'H'),\n","    ('E', 'I'),\n","    ('F', 'J'),\n","    ('H', 'K'),\n","    ('I', 'K'),\n","    ('I', 'L'),\n","    ('J', 'L'),\n","    ('G', 'J'),\n","    ('K', 'M')\n","])"],"metadata":{"id":"Q7GmP-z6Dw95"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ptn.draw()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-LebMawsD1RA","executionInfo":{"status":"ok","timestamp":1678337580302,"user_tz":-540,"elapsed":3,"user":{"displayName":"김익명","userId":"07651831371151580605"}},"outputId":"d4977d32-55c7-4886-aa7d-281203b5b939"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C -> E {}\n","C -> F {}\n","B -> E {}\n","K -> M {}\n","F -> J {}\n","J -> L {}\n","D -> B {}\n","D -> H {}\n","A -> D {}\n","G -> J {}\n","E -> I {}\n","H -> K {}\n","I -> K {}\n","I -> L {}\n"]}]},{"cell_type":"code","source":["ptn.get_descendant('A')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tumDwNu3E1jO","executionInfo":{"status":"ok","timestamp":1678337580303,"user_tz":-540,"elapsed":3,"user":{"displayName":"김익명","userId":"07651831371151580605"}},"outputId":"539dcba8-2017-4427-bf5e-5f16348b16ec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'B', 'D', 'E', 'H', 'I', 'K', 'L', 'M'}"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["ptn.get_ancestor('D')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N6fhIqMsGFid","executionInfo":{"status":"ok","timestamp":1678337581247,"user_tz":-540,"elapsed":2,"user":{"displayName":"김익명","userId":"07651831371151580605"}},"outputId":"2a9adece-784a-4be3-eff9-70c6694adf2f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'A'}"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["ptn.get_path('A', 'G')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2eamSZO2Vwk","executionInfo":{"status":"ok","timestamp":1678337581657,"user_tz":-540,"elapsed":1,"user":{"displayName":"김익명","userId":"07651831371151580605"}},"outputId":"7f880f45-6927-4775-837e-dfe0d9ee77e6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["ptn.get_path('A', 'M')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bbfkOWHx2ZIb","executionInfo":{"status":"ok","timestamp":1678337582101,"user_tz":-540,"elapsed":4,"user":{"displayName":"김익명","userId":"07651831371151580605"}},"outputId":"418842a6-a102-457a-ad3c-2e40109c167f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['A', 'D', 'B', 'E', 'I', 'K', 'M'], ['A', 'D', 'H', 'K', 'M']]"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["ptn.get_path('A', 'G', directed = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VCJ3se-t2f4h","executionInfo":{"status":"ok","timestamp":1678337582101,"user_tz":-540,"elapsed":3,"user":{"displayName":"김익명","userId":"07651831371151580605"}},"outputId":"848f089e-9c2d-47df-d4f0-e994115c6ead"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['A', 'D', 'B', 'E', 'I', 'L', 'J', 'G'],\n"," ['A', 'D', 'B', 'E', 'C', 'F', 'J', 'G'],\n"," ['A', 'D', 'B', 'E', 'C', 'F', 'J', 'G'],\n"," ['A', 'D', 'H', 'K', 'I', 'L', 'J', 'G'],\n"," ['A', 'D', 'H', 'K', 'I', 'E', 'C', 'F', 'J', 'G'],\n"," ['A', 'D', 'H', 'K', 'I', 'E', 'C', 'F', 'J', 'G'],\n"," ['A', 'D', 'B', 'E', 'I', 'L', 'J', 'G'],\n"," ['A', 'D', 'B', 'E', 'C', 'F', 'J', 'G'],\n"," ['A', 'D', 'B', 'E', 'C', 'F', 'J', 'G'],\n"," ['A', 'D', 'H', 'K', 'I', 'L', 'J', 'G'],\n"," ['A', 'D', 'H', 'K', 'I', 'E', 'C', 'F', 'J', 'G'],\n"," ['A', 'D', 'H', 'K', 'I', 'E', 'C', 'F', 'J', 'G']]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["ptn.get_d_separation({'M'}, {'E', 'I'})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"90ymGyJoGM9K","executionInfo":{"status":"ok","timestamp":1678337582797,"user_tz":-540,"elapsed":2,"user":{"displayName":"김익명","userId":"07651831371151580605"}},"outputId":"8b306dd8-e56c-4afb-f813-1db96d97b894"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'G'}"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["ptn.d_separated({'M'}, {'J'}, {'E', 'I'})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2umkodpGT2x","executionInfo":{"status":"ok","timestamp":1678337583423,"user_tz":-540,"elapsed":2,"user":{"displayName":"김익명","userId":"07651831371151580605"}},"outputId":"85ca688d-5de5-4cbc-cedc-fbb76d798c23"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":21}]}]}